{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "whole-sixth",
   "metadata": {},
   "source": [
    "## TASK_2- PART_1 EXPERIMENT LOGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-stopping",
   "metadata": {},
   "source": [
    "#### CNN architeture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-alloy",
   "metadata": {},
   "source": [
    "#### Try 1\n",
    "\n",
    "###### The below cell consist of the first CNN Netwrok I Designed for the Task using the keras sequential api, But This model seemed to be overfiiting the valiation accuracy is about 53%\n",
    "     Possible reason : The model is higly overfitted \n",
    "     Possible solution : Add some Drop out layers"
   ]
  },
  {
   "cell_type": "raw",
   "id": "monetary-edwards",
   "metadata": {},
   "source": [
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Conv2D(64,(3,3),activation = 'relu',input_shape =(56,56,1)))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Conv2D(256, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(62,activation=\"softmax\"))\n",
    "\n",
    "rlr = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, min_lr=0.0001)\n",
    "ckp = ModelCheckpoint('Unet_model.h5', monitor = 'val_loss',verbose = 1, save_best_only = True, mode = 'min')\n",
    "\n",
    "    \n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=tf.optimizers.Adam(learning_rate = 0.01), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-concord",
   "metadata": {},
   "source": [
    "#### Try-2\n",
    "##### Modification done on the above model : Add some Drop out layer to avoid the overfitting.\n",
    "\n",
    "Results : BEST VALIDATION ACC. :  70% , TRAINING Accuracy : 82%, the model seems good but Still need ,                   Imporvement to increase the validation accuracy, also the model validation accuracy is incrasing at a very lower pace.\n",
    "\n",
    "              Possibe solution : Add Skip connection, fine tunning the Dropout ratio "
   ]
  },
  {
   "cell_type": "raw",
   "id": "civic-chosen",
   "metadata": {},
   "source": [
    "model=Sequential()\n",
    "\n",
    "   \n",
    "model.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\", input_shape=(28,28,1)))\n",
    "model.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(BatchNormalization())    \n",
    "model.add(Conv2D(filters=256, kernel_size = (3,3), activation=\"relu\"))    \n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(512,activation=\"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(62,activation=\"softmax\"))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-floating",
   "metadata": {},
   "source": [
    "#### Try - 3\n",
    "\n",
    "##### Modification :       Add skip connection,fine tune the drop out ratio, Finetuning the filter size in convoltional layer, Use 'He_normal' kernel intializer\n",
    "\n",
    "       RESULTS : Validation accuracy : 73.58% , Testing accuracy : 85.76%\n",
    "       \n",
    "       This model is created using the keras functional api.since Skip connection layer can't be implemeted with keras sequential API\n",
    "       \n",
    "       \n",
    "       "
   ]
  },
  {
   "cell_type": "raw",
   "id": "textile-pledge",
   "metadata": {},
   "source": [
    "def build_model():\n",
    "  inp = Input(shape = (28,28,1))\n",
    "  x1  = Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\",  kernel_initializer= 'he_normal')(inp)\n",
    "  x1  = Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\", kernel_initializer= 'he_normal')(x1)\n",
    "  x1  = MaxPooling2D(pool_size=(2,2))(x1)\n",
    "  x1  = Dropout(0.20)(x1)\n",
    "  x1  = BatchNormalization()(x1)\n",
    "\n",
    "  x2  = Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\", kernel_initializer= 'he_normal')(x1)\n",
    "  x2  = Conv2D(filters=256, kernel_size = (3,3), activation=\"relu\", kernel_initializer= 'he_normal')(x2)\n",
    "  x2  = MaxPooling2D(pool_size=(2,2))(x2)\n",
    "  x2  = Dropout(0.25)(x2)\n",
    "  x2  = BatchNormalization()(x2)\n",
    "\n",
    "\n",
    "  #x3  = Add()([x1,x2])\n",
    "  x3  = Conv2D(filters=256, kernel_size = (3,3), activation=\"relu\", kernel_initializer= 'he_normal')(x2)\n",
    "  #x3  = Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\")(x2)\n",
    "  x3  = MaxPooling2D(pool_size=(2,2))(x3)\n",
    "  x3  = Dropout(0.25)(x3)\n",
    "  x3  = Flatten()(x3)\n",
    "  x3  = BatchNormalization()(x3)\n",
    "\n",
    "  x4  = Add()([x2,x3])                        # skip connection\n",
    "\n",
    "  x4  = Dense(512,activation=\"relu\")(x4)\n",
    "  x4  = Dropout(0.20)(x4)\n",
    "  out  = Dense(62,activation=\"softmax\")(x3)   #We have 62 classes\n",
    "  \n",
    "  return tf.keras.Model(inp,out)\n",
    "\n",
    "\n",
    "ckp = ModelCheckpoint('best_model.h5', monitor = 'val_accuracy',verbose = 1, save_best_only = True, mode = 'max')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-notification",
   "metadata": {},
   "source": [
    "####  Try-4\n",
    "\n",
    "##### IN order to futher Increase the Validation Accuracy, I have Tried to Train the Model first 30 epouchs with low argumentaion, and then 30 more epouchs on the heavy argumentaion,\n",
    "But This Try Failed , the validation accuracy is same as in Try 3 so I have to stick with the Try-3 Model."
   ]
  },
  {
   "cell_type": "raw",
   "id": "spread-fundamental",
   "metadata": {},
   "source": [
    "# Low argumentation\n",
    "train_datagen = ImageDataGenerator(  \n",
    "       \n",
    "        featurewise_center=False,  \n",
    "        samplewise_center=False,  \n",
    "        featurewise_std_normalization=False,  \n",
    "        samplewise_std_normalization=False,  \n",
    "        zca_whitening=False,  \n",
    "        rotation_range= 10,     \n",
    "        zoom_range = 0.1,  \n",
    "        width_shift_range=0.1,  \n",
    "        height_shift_range=0.1,  \n",
    "        horizontal_flip=False,  \n",
    "        vertical_flip=False,\n",
    "        validation_split = 0.2)\n",
    "\n",
    "## Heavy argumentaion\n",
    "\n",
    "train_datagen = ImageDataGenerator(  \n",
    "       \n",
    "        featurewise_center=False,  \n",
    "        samplewise_center=False,  \n",
    "        featurewise_std_normalization=False,  \n",
    "        samplewise_std_normalization=False,  \n",
    "        zca_whitening=False,  \n",
    "        rotation_range= 15,     \n",
    "        zoom_range = 0.25,  \n",
    "        width_shift_range=0.15,  \n",
    "        height_shift_range=0.15,  \n",
    "        horizontal_flip=False,  \n",
    "        vertical_flip=False,\n",
    "        validation_split = 0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-slave",
   "metadata": {},
   "source": [
    "## FineTuning the Learing rate :\n",
    "\n",
    "    \n",
    "    Intial   learing rate    :  0.01 (the model is learing fast but was hanging between 60 to 65 % accuracy ) \n",
    "    \n",
    "    Modified Learning Rate  : 0.001 (the model is learning but stuck on around 60% vallidation accuracy,but learing is quite slow)\n",
    "    \n",
    "    Final    Learing Rate     : 0.001 ( with a callback of Redunction of learing rate on pleatue with a factor of 0.5 % with minimum learing rate of 0.0001,This work best along eith the choices of the model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-colors",
   "metadata": {},
   "source": [
    "# Note : In the part 1 It is very Necessary to fine tune the model and to optimize it since we are going to use this model as the pretrained one for the Next 2 parts,\n",
    "    In the next 2 parts I have used this pretrained model.\n",
    "    and finetuned some of the argumentaion paramters which is specifed in their respective notbook also,\n",
    "    \n",
    "    ALL the Three notebooks are well Documented and explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-distance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
