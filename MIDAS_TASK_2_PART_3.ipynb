{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3-MIDAS_TASK_2\n",
    "In this notebook I have trained a pretrained model on the dataset provided.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BwFYwRi2uLw9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Lambda, MaxPooling2D, BatchNormalization, Add\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input# core layers\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau , ModelCheckpoint\n",
    "\n",
    "from platform import python_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUrKqLsht7bb",
    "outputId": "9ac32646-928e-4560-ed40-be682278ca49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 10, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,001,546\n",
      "Trainable params: 1,000,394\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x7f6f88a95d90>"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =  tf.keras.models.load_model('/content/best_model_pretrained.h5')\n",
    "model.summary()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "id": "JU8C_vJwuIBk"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'zipfile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e302e8021a0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlocal_zip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'/content/mnistTask3.zip'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mzip_ref\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_zip\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tmp/imgclassifi'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'zipfile' is not defined"
     ]
    }
   ],
   "source": [
    "local_zip = '/content/mnistTask3.zip'\n",
    "zip_ref   = zipfile.ZipFile(local_zip,'r')\n",
    "zip_ref.extractall('tmp/imgclassifi')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ob1Isu1LyZqL",
    "outputId": "bacf3d23-2f2d-437a-89d3-8b6f445028d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tmp/imgclassifi/mnistTask/0',\n",
       " 'tmp/imgclassifi/mnistTask/1',\n",
       " 'tmp/imgclassifi/mnistTask/2',\n",
       " 'tmp/imgclassifi/mnistTask/3',\n",
       " 'tmp/imgclassifi/mnistTask/4',\n",
       " 'tmp/imgclassifi/mnistTask/5',\n",
       " 'tmp/imgclassifi/mnistTask/6',\n",
       " 'tmp/imgclassifi/mnistTask/7',\n",
       " 'tmp/imgclassifi/mnistTask/8',\n",
       " 'tmp/imgclassifi/mnistTask/9']"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = os.path.join('tmp/imgclassifi/mnistTask')\n",
    "sub_dir = [os.path.join(train_dir,o) for o in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir,o))]\n",
    "sub_dir.sort()\n",
    "sub_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEW POINTS REGARDING THE DATASET\n",
    "###### The dataset has exterme noise since each subdirectories contains a mix of 0-9 images,The model will failded to achieve result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing and argumentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IIk_CbGdym1U",
    "outputId": "d972b2a4-601b-4554-c6ea-9e7f9a09379e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48006 images belonging to 10 classes.\n",
      "Found 11994 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "batchsize = 128\n",
    "EPOUCH    = 50\n",
    "\n",
    "train_datagen = ImageDataGenerator(  \n",
    "       \n",
    "        featurewise_center=False,  \n",
    "        samplewise_center=False,  \n",
    "        featurewise_std_normalization=False,  \n",
    "        samplewise_std_normalization=False,  \n",
    "        zca_whitening=False,  \n",
    "        rotation_range= 10,     \n",
    "        zoom_range = 0.1,  \n",
    "        width_shift_range=0.1,  \n",
    "        height_shift_range=0.1,  \n",
    "        horizontal_flip=False,  \n",
    "        vertical_flip=False,\n",
    "        validation_split = 0.2)\n",
    "\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  # This is the source directory for training images\n",
    "        target_size=(28,28),  # All images will be resized to 28*28\n",
    "        batch_size=batchsize,\n",
    "        color_mode = \"grayscale\",\n",
    "        class_mode='categorical',\n",
    "        subset = 'training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  # This is the source directory for training images\n",
    "        target_size=(28,28),  # All images will be resized to 28*28\n",
    "        batch_size=batchsize,\n",
    "        color_mode = \"grayscale\",\n",
    "        class_mode='categorical',\n",
    "        subset = 'validation')\n",
    "\n",
    "rlr = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, min_lr=0.0001)   # minimun leraing rate 0.0001\n",
    "ckp = ModelCheckpoint('best_model.h5', monitor = 'val_accuracy',verbose = 1, save_best_only = True, mode = 'max')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training The  pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OndYHcNdzPYg",
    "outputId": "429ad401-d830-46f3-96fb-625aa8e903d2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "375/375 [==============================] - 62s 85ms/step - loss: 2.9194 - accuracy: 0.1049 - val_loss: 2.3203 - val_accuracy: 0.1131\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.11314, saving model to best_model.h5\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 30s 80ms/step - loss: 2.4330 - accuracy: 0.1095 - val_loss: 2.2952 - val_accuracy: 0.1080\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.11314\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 31s 82ms/step - loss: 2.3732 - accuracy: 0.1088 - val_loss: 2.2992 - val_accuracy: 0.1125\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.11314\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3333 - accuracy: 0.1117 - val_loss: 2.2789 - val_accuracy: 0.1079\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.11314\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3125 - accuracy: 0.1113 - val_loss: 2.2694 - val_accuracy: 0.1117\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.11314\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 31s 82ms/step - loss: 2.2995 - accuracy: 0.1131 - val_loss: 2.2700 - val_accuracy: 0.1106\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.11314\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 30s 80ms/step - loss: 2.2937 - accuracy: 0.1117 - val_loss: 2.2629 - val_accuracy: 0.1174\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.11314 to 0.11739, saving model to best_model.h5\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.2851 - accuracy: 0.1143 - val_loss: 2.2596 - val_accuracy: 0.1116\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.11739\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.2782 - accuracy: 0.1145 - val_loss: 2.2570 - val_accuracy: 0.1052\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.11739\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.2725 - accuracy: 0.1146 - val_loss: 2.2549 - val_accuracy: 0.1088\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.11739\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 30s 80ms/step - loss: 2.2662 - accuracy: 0.1148 - val_loss: 2.2528 - val_accuracy: 0.1084\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.11739\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.2621 - accuracy: 0.1162 - val_loss: 2.2498 - val_accuracy: 0.1116\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.11739\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 31s 81ms/step - loss: 2.2611 - accuracy: 0.1160 - val_loss: 2.2470 - val_accuracy: 0.1108\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.11739\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 31s 81ms/step - loss: 2.2558 - accuracy: 0.1162 - val_loss: 2.2456 - val_accuracy: 0.1129\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.11739\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.2563 - accuracy: 0.1163 - val_loss: 2.2443 - val_accuracy: 0.1096\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.11739\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.2541 - accuracy: 0.1139 - val_loss: 2.2431 - val_accuracy: 0.1052\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.11739\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 31s 81ms/step - loss: 2.2527 - accuracy: 0.1155 - val_loss: 2.2409 - val_accuracy: 0.1122\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.11739\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 31s 82ms/step - loss: 2.2492 - accuracy: 0.1179 - val_loss: 2.2409 - val_accuracy: 0.1108\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.11739\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.2483 - accuracy: 0.1162 - val_loss: 2.2390 - val_accuracy: 0.1120\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.11739\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 31s 82ms/step - loss: 2.2479 - accuracy: 0.1162 - val_loss: 2.2390 - val_accuracy: 0.1067\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.11739\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 30s 80ms/step - loss: 2.2467 - accuracy: 0.1173 - val_loss: 2.2378 - val_accuracy: 0.1111\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.11739\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.2444 - accuracy: 0.1160 - val_loss: 2.2360 - val_accuracy: 0.1066\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.11739\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 31s 81ms/step - loss: 2.2425 - accuracy: 0.1207 - val_loss: 2.2347 - val_accuracy: 0.1124\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.11739\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.2423 - accuracy: 0.1188 - val_loss: 2.2338 - val_accuracy: 0.1089\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.11739\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.2417 - accuracy: 0.1178 - val_loss: 2.2322 - val_accuracy: 0.1116\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.11739\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.2406 - accuracy: 0.1175 - val_loss: 2.2323 - val_accuracy: 0.1084\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.11739\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.2393 - accuracy: 0.1168 - val_loss: 2.2320 - val_accuracy: 0.1079\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.11739\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 31s 81ms/step - loss: 2.2371 - accuracy: 0.1196 - val_loss: 2.2301 - val_accuracy: 0.1104\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.11739\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.2371 - accuracy: 0.1175 - val_loss: 2.2287 - val_accuracy: 0.1073\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.11739\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.2366 - accuracy: 0.1172 - val_loss: 2.2294 - val_accuracy: 0.1074\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.11739\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 30s 80ms/step - loss: 2.2351 - accuracy: 0.1179 - val_loss: 2.2293 - val_accuracy: 0.1092\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.11739\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 31s 81ms/step - loss: 2.2327 - accuracy: 0.1218 - val_loss: 2.2283 - val_accuracy: 0.1071\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.11739\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 31s 81ms/step - loss: 2.2329 - accuracy: 0.1187 - val_loss: 2.2266 - val_accuracy: 0.1118\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.11739\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.2325 - accuracy: 0.1206 - val_loss: 2.2262 - val_accuracy: 0.1131\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.11739\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 30s 80ms/step - loss: 2.2323 - accuracy: 0.1189 - val_loss: 2.2268 - val_accuracy: 0.1126\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.11739\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.2316 - accuracy: 0.1195 - val_loss: 2.2254 - val_accuracy: 0.1094\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.11739\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.2290 - accuracy: 0.1205 - val_loss: 2.2258 - val_accuracy: 0.1075\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.11739\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.2303 - accuracy: 0.1187 - val_loss: 2.2248 - val_accuracy: 0.1109\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.11739\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.2288 - accuracy: 0.1210 - val_loss: 2.2259 - val_accuracy: 0.1054\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.11739\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.2284 - accuracy: 0.1223 - val_loss: 2.2240 - val_accuracy: 0.1116\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.11739\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.2271 - accuracy: 0.1209 - val_loss: 2.2245 - val_accuracy: 0.1078\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.11739\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 31s 82ms/step - loss: 2.2271 - accuracy: 0.1208 - val_loss: 2.2247 - val_accuracy: 0.1076\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.11739\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.2268 - accuracy: 0.1220 - val_loss: 2.2230 - val_accuracy: 0.1078\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.11739\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.2255 - accuracy: 0.1223 - val_loss: 2.2226 - val_accuracy: 0.1134\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.11739\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 31s 82ms/step - loss: 2.2238 - accuracy: 0.1220 - val_loss: 2.2231 - val_accuracy: 0.1131\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.11739\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 31s 82ms/step - loss: 2.2258 - accuracy: 0.1230 - val_loss: 2.2227 - val_accuracy: 0.1089\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.11739\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 31s 82ms/step - loss: 2.2253 - accuracy: 0.1185 - val_loss: 2.2229 - val_accuracy: 0.1110\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.11739\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 31s 82ms/step - loss: 2.2246 - accuracy: 0.1220 - val_loss: 2.2226 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.11739\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 31s 82ms/step - loss: 2.2237 - accuracy: 0.1207 - val_loss: 2.2204 - val_accuracy: 0.1114\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.11739\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 31s 82ms/step - loss: 2.2238 - accuracy: 0.1222 - val_loss: 2.2217 - val_accuracy: 0.1148\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.11739\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,steps_per_epoch= 48006/batchsize,epochs = EPOUCH ,verbose=1,validation_data=validation_generator, callbacks=[rlr,ckp])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results \n",
    "Training accuracy  = 0.122\n",
    "validation accuracy = 0.1148"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Mnist dataset\n",
    "\n",
    "preproceesing the testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "TKOVeZoHBKUt"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "X_test = X_test/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding for the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "F8P-aR04BVs-"
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "n_classes = 10\n",
    "Y_test = np_utils.to_categorical(Y_test, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2FpMopocDTKS",
    "outputId": "7fe86d43-aace-4105-99c3-7047bf74c56c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 2.3536 - accuracy: 0.0684\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Result \n",
    "ACCuracy = 0.0684 (As expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIJ5leCgDmCA"
   },
   "source": [
    "# FINAL OVERVIEW\n",
    "\n",
    "As expected the Model Performance is Dead, we unable to achieve even 1% accuracy on the Mnist test set, As already mentioned the Datset is Highly noisy.\n",
    "\n",
    "# Method to achieve The result\n",
    "\n",
    "In order to achieve the good result we have to preform the Data cleansing, in order to reduce the noise(making a balanced dataset by puuting each image in its respective directory) we can perform Follwing operations,\n",
    "\n",
    "1) Using The k-means custering alogorithms we can cluster the same type of image in the a particular subdirectory.It can achieve around the 90 to 95% of accuracy.\n",
    "2) Use the previous model part 2 to label the imaage as its is highly optimized Model with the validation accuracy around 99.5,then perform the K-mean clustering on the 0.5% of the data that will be classified wrong by the Part-2 Model.\n",
    "\n",
    "As far as My understanding is concerned The second method will be more beneficial since the specification of images in the dataset is compeletely matched with the Mnist dataset, and we can easliy label the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "MIDAS PART 3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
